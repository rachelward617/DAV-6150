{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sara Ferrari, Michael Vizelman, and Rachel Ward - Final Project Proposal\n",
    "\n",
    "## DAV 6150\n",
    "\n",
    "## Introduction\n",
    "\n",
    "For this project, we will be using data from the [2019 Census Current Population Survey](https://www.census.gov/data/datasets/time-series/demo/cps/cps-asec.html) to predict whether or not a person will receive financial assistance from the government. Our project will focus on census data that is available for millenials. The dataset we have is comprised of 800 variables, but we will be selecting a subset of these that we believe could prove relevant for our population of interest and our goal. \n",
    "\n",
    "In the United States, there is no generalized education on finance (at least in public education), so many individuals who graduate high school or even college, do not have a basic understanding of how to live within their means. Our project will attempt to predict whether an individual will receive financial assistance from the government. This would be useful if the government were to offer a free program on financial education to individuals who are likely to require financial assistance.  By using millenials for this project, we would be getting a subset of the U.S. population which has recently finished schooling and is now in the workforce, but is still in the process of settling down. If the financial education program were successful, reaching millenials at this stage in their life could prove to be a positive influence on their financial future. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Questions\n",
    "\n",
    "**Will an individual require financial assistance from the government?**\n",
    "\n",
    "Understanding if an individual would require financial assistance will help governments determine who should be eligible for a free financial education course. Alternately, this information could be used by a bank as a supporting tool when deciding whether or not to issue services such as a credit card or a loan to an individual. If we predict that an individual will need financial assistance, that would decrease his/her probability of (re)payment, and hence decrease the probability that the bank will offer the loan or credit card. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data to be Used\n",
    "\n",
    "As stated above, we will be using a subset of the [2019 Census Current Population Survey](https://www.census.gov/data/datasets/time-series/demo/cps/cps-asec.html). \n",
    "From this dataset we will extract only the data referred to people considered \"Millenials\", which are all born from 1981 to 1996 (according to this [article](https://www.pewresearch.org/fact-tank/2020/04/28/millennials-overtake-baby-boomers-as-americas-largest-generation/#:~:text=As%20of%20July%201%2C%202019,to%2073%20numbered%2071.6%20million.)).In our dataset we have 34,747 observations referring to this particular group.   \n",
    "Since the original dataset is extremely large, we cannot upload it to GitHub. Hence, we will first download the dataset locally and parse out the information we are looking for using Python. We will then upload a clean version of this dataset to GitHub for use in our project. All the steps for this process will be provided and a reader of our project would be able to reproduce our results following our steps. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach\n",
    "\n",
    "We will take the following approach to answer our research questions:  \n",
    "1. Use Python to select the subset of our dataset that is of interest.  \n",
    "2. Upload the subset of the dataset to our GitHub repository. read the dataset from our repository, and load the data into a Pandas dataframe.   \n",
    "3. Perform EDA work as necessary.  \n",
    "4. Perform any required data preparation work, including any feature engineering or standardization adjustments we deem necessary for our work.  \n",
    "5. Apply our knowledge of feature selection and/or dimensionality reduction techniques to identify at least four (4) explanatory variables for inclusion within our models. Split the data into training and testing subsets.  \n",
    "6. Use the training subset to construct the following three machine learning models which are all appropriate for classification:  \n",
    " -  Binary Logistic Regression  \n",
    " -  Random Forests\n",
    " -  KNN model   \n",
    "7. Select our preferred model. Considering we expect our target variable to be imbalanced, we are going to use not only the accuracy of our models but also the recall and the F1 score. It is reasonable to assume that the cost of not giving help to someone in need is greater than giving help to someone who doesn't need it.  Additionally, in the use case with a bank, it would be more harmful to predict that someone would not require financial assistance and have the bank grant a loan when the individual actually will require financial assistance. Meaning, we should be minimizing the false-negative predictions we generate, and the metric we should be looking at and maximizing is Recall (TP/(TP+FN)).   \n",
    "8. Evaluate the performance on the test data.   \n",
    "9. Construct an ensemble model comprising all of the models built previously. Explain how this model works. Compare the results of this ensemble approach to the results of our other models.   \n",
    "10. Summarize our work and clearly state the conclusions of our research.  \n",
    "\n",
    "As part of our work, we will use a chi square test of independence and a correlation matrix to evaluate the relationships with the target variable. We will also use side-by-side bar plots to show the relationship between our target variable and our demographic variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Member Responsibilities ##\n",
    "**Sara Ferrari:**  \n",
    "+ Find and collect the data for the project's research topic.   \n",
    "+ Ensure data consistency - verify all data is managed correctly after the upload of the data.    \n",
    "+ EDA and preliminary statistical analysis     \n",
    "+ Work in parallel on project code according to the steps described above in the Approach section. Review other team member's work, to pick the most efficient code result.  \n",
    "\n",
    "**Michael Vizelman:**  \n",
    "- Find and collect the data for the project's research topic.\n",
    "- Creation of the models and ensemble model.    \n",
    "- Edit the project documentation (notes and text sections).   \n",
    "- Work in parallel on project code according to the steps described above in the Approach section. Review other team member's work, to pick the most efficient code result. \n",
    "\n",
    "**Rachel Ward:**\n",
    "- Find and collect the data for the project's research topic.\n",
    "- Upload the collected data to a repository that allows the reproduction of the project work, and upload the data correctly to the Jupyter notebook containing the project.    \n",
    "- Creation of the models and ensemble model.   \n",
    "- Work in parallel on project code according to the steps described above in the Approach section. Review other team member's work, to pick the most efficient code result. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
